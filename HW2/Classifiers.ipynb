{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #2: classification\n",
    "Data source: http://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('../data/4year.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bankruptcy'] = (df['class']==b'1')\n",
    "df.drop(columns=['class'], inplace=True)\n",
    "df.columns = ['X{0:02d}'.format(k) for k in range(1,65)] + ['bankruptcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9773.000000</td>\n",
       "      <td>9792.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.792000e+03</td>\n",
       "      <td>9771.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9776.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9178.000000</td>\n",
       "      <td>9760.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.043019</td>\n",
       "      <td>0.596404</td>\n",
       "      <td>0.130959</td>\n",
       "      <td>8.136600</td>\n",
       "      <td>6.465164e+01</td>\n",
       "      <td>-0.059273</td>\n",
       "      <td>0.059446</td>\n",
       "      <td>19.884016</td>\n",
       "      <td>1.882296</td>\n",
       "      <td>0.389040</td>\n",
       "      <td>...</td>\n",
       "      <td>7.686330e+03</td>\n",
       "      <td>-0.992263</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>1.133287</td>\n",
       "      <td>0.856053</td>\n",
       "      <td>118.156064</td>\n",
       "      <td>25.194430</td>\n",
       "      <td>2.015157e+03</td>\n",
       "      <td>8.660813</td>\n",
       "      <td>35.949619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.359321</td>\n",
       "      <td>4.587122</td>\n",
       "      <td>4.559074</td>\n",
       "      <td>290.647281</td>\n",
       "      <td>1.475939e+04</td>\n",
       "      <td>6.812754</td>\n",
       "      <td>0.533344</td>\n",
       "      <td>698.697015</td>\n",
       "      <td>17.674650</td>\n",
       "      <td>4.590299</td>\n",
       "      <td>...</td>\n",
       "      <td>7.605261e+04</td>\n",
       "      <td>77.007971</td>\n",
       "      <td>8.945365</td>\n",
       "      <td>8.038201</td>\n",
       "      <td>26.393305</td>\n",
       "      <td>3230.316692</td>\n",
       "      <td>1099.260821</td>\n",
       "      <td>1.171461e+05</td>\n",
       "      <td>60.838202</td>\n",
       "      <td>483.318623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.458000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>-0.045319</td>\n",
       "      <td>-3.794600e+05</td>\n",
       "      <td>-486.820000</td>\n",
       "      <td>-12.458000</td>\n",
       "      <td>-1.848200</td>\n",
       "      <td>-0.032371</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.132200e+05</td>\n",
       "      <td>-7522.100000</td>\n",
       "      <td>-597.420000</td>\n",
       "      <td>-30.892000</td>\n",
       "      <td>-284.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.656000</td>\n",
       "      <td>-1.496500e+04</td>\n",
       "      <td>-0.024390</td>\n",
       "      <td>-0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.263145</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>-5.121700e+01</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>1.006675</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184000e+01</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>0.885722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.356325</td>\n",
       "      <td>4.267700</td>\n",
       "      <td>4.323400e+01</td>\n",
       "      <td>2.938800</td>\n",
       "      <td>2.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.041364</td>\n",
       "      <td>0.467740</td>\n",
       "      <td>0.199290</td>\n",
       "      <td>1.591800</td>\n",
       "      <td>-5.557600e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048820</td>\n",
       "      <td>1.088700</td>\n",
       "      <td>1.161300</td>\n",
       "      <td>0.510450</td>\n",
       "      <td>...</td>\n",
       "      <td>9.503300e+02</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.098026</td>\n",
       "      <td>0.958305</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>9.482000</td>\n",
       "      <td>6.283550</td>\n",
       "      <td>7.472900e+01</td>\n",
       "      <td>4.848900</td>\n",
       "      <td>4.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.111130</td>\n",
       "      <td>0.689255</td>\n",
       "      <td>0.410670</td>\n",
       "      <td>2.880400</td>\n",
       "      <td>5.573200e+01</td>\n",
       "      <td>0.065322</td>\n",
       "      <td>0.126940</td>\n",
       "      <td>2.691000</td>\n",
       "      <td>1.970225</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>...</td>\n",
       "      <td>4.694550e+03</td>\n",
       "      <td>0.117170</td>\n",
       "      <td>0.242680</td>\n",
       "      <td>0.996163</td>\n",
       "      <td>0.211790</td>\n",
       "      <td>19.506000</td>\n",
       "      <td>9.938200</td>\n",
       "      <td>1.233450e+02</td>\n",
       "      <td>8.363800</td>\n",
       "      <td>9.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.482000</td>\n",
       "      <td>446.910000</td>\n",
       "      <td>22.769000</td>\n",
       "      <td>27146.000000</td>\n",
       "      <td>1.034100e+06</td>\n",
       "      <td>322.200000</td>\n",
       "      <td>38.618000</td>\n",
       "      <td>53209.000000</td>\n",
       "      <td>1704.800000</td>\n",
       "      <td>12.602000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123700e+06</td>\n",
       "      <td>112.020000</td>\n",
       "      <td>226.760000</td>\n",
       "      <td>668.750000</td>\n",
       "      <td>1661.000000</td>\n",
       "      <td>251570.000000</td>\n",
       "      <td>108000.000000</td>\n",
       "      <td>1.077900e+07</td>\n",
       "      <td>5662.400000</td>\n",
       "      <td>21153.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X01          X02          X03           X04           X05  \\\n",
       "count  9791.000000  9791.000000  9791.000000   9749.000000  9.771000e+03   \n",
       "mean      0.043019     0.596404     0.130959      8.136600  6.465164e+01   \n",
       "std       0.359321     4.587122     4.559074    290.647281  1.475939e+04   \n",
       "min     -12.458000     0.000000  -445.910000     -0.045319 -3.794600e+05   \n",
       "25%       0.001321     0.263145     0.020377      1.047000 -5.121700e+01   \n",
       "50%       0.041364     0.467740     0.199290      1.591800 -5.557600e-02   \n",
       "75%       0.111130     0.689255     0.410670      2.880400  5.573200e+01   \n",
       "max      20.482000   446.910000    22.769000  27146.000000  1.034100e+06   \n",
       "\n",
       "               X06          X07           X08          X09          X10  ...  \\\n",
       "count  9791.000000  9791.000000   9773.000000  9792.000000  9791.000000  ...   \n",
       "mean     -0.059273     0.059446     19.884016     1.882296     0.389040  ...   \n",
       "std       6.812754     0.533344    698.697015    17.674650     4.590299  ...   \n",
       "min    -486.820000   -12.458000     -1.848200    -0.032371  -445.910000  ...   \n",
       "25%      -0.000578     0.003004      0.428300     1.006675     0.294440  ...   \n",
       "50%       0.000000     0.048820      1.088700     1.161300     0.510450  ...   \n",
       "75%       0.065322     0.126940      2.691000     1.970225     0.714290  ...   \n",
       "max     322.200000    38.618000  53209.000000  1704.800000    12.602000  ...   \n",
       "\n",
       "                X55          X56          X57          X58          X59  \\\n",
       "count  9.792000e+03  9771.000000  9791.000000  9776.000000  9791.000000   \n",
       "mean   7.686330e+03    -0.992263     0.035022     1.133287     0.856053   \n",
       "std    7.605261e+04    77.007971     8.945365     8.038201    26.393305   \n",
       "min   -7.132200e+05 -7522.100000  -597.420000   -30.892000  -284.380000   \n",
       "25%    2.184000e+01     0.003121     0.008768     0.885722     0.000000   \n",
       "50%    9.503300e+02     0.043679     0.098026     0.958305     0.002129   \n",
       "75%    4.694550e+03     0.117170     0.242680     0.996163     0.211790   \n",
       "max    6.123700e+06   112.020000   226.760000   668.750000  1661.000000   \n",
       "\n",
       "                 X60            X61           X62          X63           X64  \n",
       "count    9178.000000    9760.000000  9.771000e+03  9749.000000   9561.000000  \n",
       "mean      118.156064      25.194430  2.015157e+03     8.660813     35.949619  \n",
       "std      3230.316692    1099.260821  1.171461e+05    60.838202    483.318623  \n",
       "min         0.000000     -12.656000 -1.496500e+04    -0.024390     -0.000015  \n",
       "25%         5.356325       4.267700  4.323400e+01     2.938800      2.012900  \n",
       "50%         9.482000       6.283550  7.472900e+01     4.848900      4.041600  \n",
       "75%        19.506000       9.938200  1.233450e+02     8.363800      9.413500  \n",
       "max    251570.000000  108000.000000  1.077900e+07  5662.400000  21153.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>bankruptcy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159290</td>\n",
       "      <td>0.46240</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>1.1683</td>\n",
       "      <td>-44.853</td>\n",
       "      <td>0.467020</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.82895</td>\n",
       "      <td>1.1223</td>\n",
       "      <td>0.38330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108990</td>\n",
       "      <td>0.41557</td>\n",
       "      <td>0.89101</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>7.7928</td>\n",
       "      <td>4.9914</td>\n",
       "      <td>119.810</td>\n",
       "      <td>3.0465</td>\n",
       "      <td>3.0560</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.127430</td>\n",
       "      <td>0.46243</td>\n",
       "      <td>0.26917</td>\n",
       "      <td>1.7517</td>\n",
       "      <td>7.597</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>-0.127430</td>\n",
       "      <td>1.16250</td>\n",
       "      <td>1.2944</td>\n",
       "      <td>0.53757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089372</td>\n",
       "      <td>-0.23704</td>\n",
       "      <td>1.06250</td>\n",
       "      <td>0.150410</td>\n",
       "      <td>5.4327</td>\n",
       "      <td>3.4629</td>\n",
       "      <td>100.970</td>\n",
       "      <td>3.6150</td>\n",
       "      <td>3.4725</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.070488</td>\n",
       "      <td>0.23570</td>\n",
       "      <td>0.52781</td>\n",
       "      <td>3.2393</td>\n",
       "      <td>125.680</td>\n",
       "      <td>0.163670</td>\n",
       "      <td>0.086895</td>\n",
       "      <td>2.87180</td>\n",
       "      <td>1.0574</td>\n",
       "      <td>0.67689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>0.10413</td>\n",
       "      <td>0.94571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.1070</td>\n",
       "      <td>3.3808</td>\n",
       "      <td>76.076</td>\n",
       "      <td>4.7978</td>\n",
       "      <td>4.7818</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136760</td>\n",
       "      <td>0.40538</td>\n",
       "      <td>0.31543</td>\n",
       "      <td>1.8705</td>\n",
       "      <td>19.115</td>\n",
       "      <td>0.504970</td>\n",
       "      <td>0.136760</td>\n",
       "      <td>1.45390</td>\n",
       "      <td>1.1144</td>\n",
       "      <td>0.58938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102630</td>\n",
       "      <td>0.23203</td>\n",
       "      <td>0.89737</td>\n",
       "      <td>0.073024</td>\n",
       "      <td>6.1384</td>\n",
       "      <td>4.2241</td>\n",
       "      <td>88.299</td>\n",
       "      <td>4.1337</td>\n",
       "      <td>4.6484</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.110080</td>\n",
       "      <td>0.69793</td>\n",
       "      <td>0.18878</td>\n",
       "      <td>1.2713</td>\n",
       "      <td>-15.344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.110080</td>\n",
       "      <td>0.43282</td>\n",
       "      <td>1.7350</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439880</td>\n",
       "      <td>-0.36440</td>\n",
       "      <td>0.57153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.8010</td>\n",
       "      <td>2.7925</td>\n",
       "      <td>146.390</td>\n",
       "      <td>2.4934</td>\n",
       "      <td>15.0360</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X01      X02      X03     X04      X05       X06       X07      X08  \\\n",
       "0  0.159290  0.46240  0.07773  1.1683  -44.853  0.467020  0.189480  0.82895   \n",
       "1 -0.127430  0.46243  0.26917  1.7517    7.597  0.000925 -0.127430  1.16250   \n",
       "2  0.070488  0.23570  0.52781  3.2393  125.680  0.163670  0.086895  2.87180   \n",
       "3  0.136760  0.40538  0.31543  1.8705   19.115  0.504970  0.136760  1.45390   \n",
       "4 -0.110080  0.69793  0.18878  1.2713  -15.344  0.000000 -0.110080  0.43282   \n",
       "\n",
       "      X09      X10  ...       X56      X57      X58       X59      X60  \\\n",
       "0  1.1223  0.38330  ...  0.108990  0.41557  0.89101  0.001422   7.7928   \n",
       "1  1.2944  0.53757  ... -0.089372 -0.23704  1.06250  0.150410   5.4327   \n",
       "2  1.0574  0.67689  ...  0.054286  0.10413  0.94571  0.000000   7.1070   \n",
       "3  1.1144  0.58938  ...  0.102630  0.23203  0.89737  0.073024   6.1384   \n",
       "4  1.7350  0.30207  ...  0.439880 -0.36440  0.57153  0.000000  18.8010   \n",
       "\n",
       "      X61      X62     X63      X64  bankruptcy  \n",
       "0  4.9914  119.810  3.0465   3.0560       False  \n",
       "1  3.4629  100.970  3.6150   3.4725       False  \n",
       "2  3.3808   76.076  4.7978   4.7818       False  \n",
       "3  4.2241   88.299  4.1337   4.6484       False  \n",
       "4  2.7925  146.390  2.4934  15.0360       False  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.bankruptcy == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "df.isna().sum()\n",
    "X_imp = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15929, 0.4624, 0.07773, ..., 119.81, 3.0465, 3.056],\n",
       "       [-0.12743, 0.46243, 0.26917, ..., 100.97, 3.615, 3.4725],\n",
       "       [0.070488, 0.2357, 0.52781, ..., 76.076, 4.7978, 4.7818],\n",
       "       ...,\n",
       "       [-0.23829, 0.62708, 0.090374, ..., 88.883, 4.1065, 0.79501],\n",
       "       [0.097188, 0.753, -0.32768, ..., 217.03, 1.6818, 1.3191],\n",
       "       [0.021416, 0.48678, 0.14894, ..., 98.421, 3.7085, 4.9295]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imp[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = X_imp[:, :-1], X_imp[:, -1]\n",
    "y = y.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 64)\n",
      "(2938, 64)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as skpre\n",
    "\n",
    "stdsc = skpre.StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "print(X_train_std.shape)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "print(X_test_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the 2 most important features\n",
    "using Logistic Regression with L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(2,)\n",
      "(14,)\n",
      "(42,)\n",
      "(53,)\n",
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "c_val = [0.001, 0.01, 0.1, 1, 5, 10]\n",
    "for c in c_val:\n",
    "    lr = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    print(lr.coef_[lr.coef_!=0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1', C=0.01, solver='liblinear') # complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_[lr.coef_!=0].shape # check the number of the features with non-zero weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine X_train_std and X_test_std\n",
    "X_train_std = X_train_std[:, lr.coef_[0]!=0]\n",
    "X_test_std = X_test_std[:, lr.coef_[0]!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LR / SVM / Decision Tree below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of C is 0.001: 0.9474759264662971\n",
      "Test accuracy of C is 0.001: 0.9472430224642614\n",
      "\n",
      "Training accuracy of C is 0.01: 0.9474759264662971\n",
      "Test accuracy of C is 0.01: 0.9469026548672567\n",
      "\n",
      "Training accuracy of C is 0.1: 0.946892325649256\n",
      "Test accuracy of C is 0.1: 0.9469026548672567\n",
      "\n",
      "Training accuracy of C is 1: 0.946892325649256\n",
      "Test accuracy of C is 1: 0.9469026548672567\n",
      "\n",
      "Training accuracy of C is 5: 0.946892325649256\n",
      "Test accuracy of C is 5: 0.9469026548672567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_val = [0.001, 0.01, 0.1, 1, 5]\n",
    "for c in c_val:\n",
    "    lr = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    print('Training accuracy of C is {}: {}'.format(c, lr.score(X_train_std, y_train)))\n",
    "    print('Test accuracy of C is {}: {}'.format(c, lr.score(X_test_std, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of C is 0.001: 0.9474759264662971\n",
      "Test accuracy of C is 0.001: 0.9472430224642614\n",
      "\n",
      "Training accuracy of C is 0.01: 0.9474759264662971\n",
      "Test accuracy of C is 0.01: 0.9472430224642614\n",
      "\n",
      "Training accuracy of C is 0.1: 0.9474759264662971\n",
      "Test accuracy of C is 0.1: 0.9472430224642614\n",
      "\n",
      "Training accuracy of C is 1: 0.9482054274875985\n",
      "Test accuracy of C is 1: 0.9472430224642614\n",
      "\n",
      "Training accuracy of C is 5: 0.948497227896119\n",
      "Test accuracy of C is 5: 0.9462219196732471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SVM, gamma='scale'\n",
    "c_val = [0.001, 0.01, 0.1, 1, 5]\n",
    "for c in c_val:\n",
    "    svm = SVC(C=c, gamma='scale')\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    print('Training accuracy of C is {}: {}'.format(c, svm.score(X_train_std, y_train)))\n",
    "    print('Test accuracy of C is {}: {}'.format(c, svm.score(X_test_std, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of C is 0.001: 0.9474759264662971\n",
      "Test accuracy of C is 0.001: 0.9472430224642614\n",
      "\n",
      "Training accuracy of C is 0.01: 0.9474759264662971\n",
      "Test accuracy of C is 0.01: 0.9472430224642614\n",
      "\n",
      "Training accuracy of C is 0.1: 0.9474759264662971\n",
      "Test accuracy of C is 0.1: 0.9472430224642614\n",
      "\n",
      "Training accuracy of C is 1: 0.9482054274875985\n",
      "Test accuracy of C is 1: 0.9472430224642614\n",
      "\n",
      "Training accuracy of C is 5: 0.948497227896119\n",
      "Test accuracy of C is 5: 0.9462219196732471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SVM, gamma='auto' \n",
    "c_val = [0.001, 0.01, 0.1, 1, 5]\n",
    "for c in c_val:\n",
    "    svm = SVC(C=c, gamma='auto')\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    print('Training accuracy of C is {}: {}'.format(c, svm.score(X_train_std, y_train)))\n",
    "    print('Test accuracy of C is {}: {}'.format(c, svm.score(X_test_std, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of tree depth is 1: 0.9474759264662971\n",
      "Test accuracy of tree depth is 1: 0.9472430224642614\n",
      "\n",
      "Training accuracy of tree depth is 3: 0.9601692442369419\n",
      "Test accuracy of tree depth is 3: 0.9560925799863853\n",
      "\n",
      "Training accuracy of tree depth is 5: 0.9676101546542165\n",
      "Test accuracy of tree depth is 5: 0.9601769911504425\n",
      "\n",
      "Training accuracy of tree depth is 7: 0.974029763641669\n",
      "Test accuracy of tree depth is 7: 0.955071477195371\n",
      "\n",
      "Training accuracy of tree depth is 9: 0.9784067697694777\n",
      "Test accuracy of tree depth is 9: 0.9557522123893806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Decision Tree\n",
    "tree_depth = np.arange(1, 10, 2)\n",
    "for d in tree_depth:\n",
    "    dcs_tree = DecisionTreeClassifier(max_depth=d)\n",
    "    dcs_tree.fit(X_train_std, y_train)\n",
    "    print('Training accuracy of tree depth is {}: {}'.format(d, dcs_tree.score(X_train_std, y_train)))\n",
    "    print('Test accuracy of tree depth is {}: {}'.format(d, dcs_tree.score(X_test_std, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=0.1, solver='liblinear') # complete\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "plot_decision_regions(X=X_combined_std, y=y_combined,\n",
    "                      classifier=lr, test_idx=range(0, 50))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/03_01.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
